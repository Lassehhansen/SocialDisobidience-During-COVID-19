{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DOWNLOADING TWEETS\n",
    "# Creating list to append tweet data to\n",
    "tweets_list17 = []\n",
    "#Choosing runtime of the tweets, and text search\n",
    "\n",
    "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('covid19 OR covid19dk OR corona OR coronadk OR edpidemi OR pandemi OR virus since:2020-03-01 until:2021-04-01 lang:da').get_items()):\n",
    "    tweets_list17.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.likeCount, tweet.retweetCount, tweet.mentionedUsers, tweet.lang, tweet.url ])\n",
    "    \n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_list17 = pd.DataFrame(tweets_list17, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'Likes', 'Retweets', \"MentionedUsers\", \"Language\", \"Url\"])\n",
    "\n",
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #Remove @ sign\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Remove http links\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Remove hashtag sign but keep the text\n",
    "    return tweet\n",
    "\n",
    "import re\n",
    "def remove_emojis(data):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', data)\n",
    "\n",
    "tweets_list17['Tweet'] = tweets_list17['Text'].map(lambda x: cleaner(x))\n",
    "\n",
    "tweets_list17['Tweet_NO_EMOJ'] = tweets_list17['Tweet'].map(lambda x: remove_emojis(x))\n",
    "\n",
    "from langdetect import detect\n",
    "tweets_list17['LangDetect'] =tweets_list17['Tweet_NO_EMOJ'].apply(detect)\n",
    "tweets_list17 = tweets_list17.loc[tweets_list17['LangDetect'] == 'da']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using Bert Tone \n",
    "from danlp.models import load_bert_tone_model\n",
    "classifier_to = load_bert_tone_model()\n",
    "tweets_list17['Bert_Polarity'] = tweets_list17['Tweet'].apply(classifier_to.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lassehansen/opt/anaconda3/lib/python3.8/site-packages/danlp/models/bert_models.py:180: UserWarning: Maximum length for sequence exceeded, truncation may result in unexpected results. Consider running the model on a shorter sequenze then 512 tokens\n",
      "  warnings.warn('Maximum length for sequence exceeded, truncation may result in unexpected results. Consider running the model on a shorter sequenze then {} tokens'.format(max_lenght))\n"
     ]
    }
   ],
   "source": [
    "#Using Bert Emotion\n",
    "tweet_test1 = pd.read_csv(\"tweet_test1.csv\")\n",
    "\n",
    "from danlp.models import load_bert_emotion_model\n",
    "classifier_da = load_bert_emotion_model()\n",
    "Bert_E = tweet_test1['Tweet'].apply(classifier_da.predict)\n",
    "tweet_test1 = tweet_test1.assign(Bert_Emotion=Bert_E.values) # assign values to column 'c'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving Tweet list with analysis\n",
    "tweet_list_Danmark.to_csv(\"tweet_list_Danmark_1.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
