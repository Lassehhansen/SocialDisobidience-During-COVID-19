---
title: "Twitter Analysis Preprocessing"
author: "Lasse Hansen"
date: "5/12/2021"
output: html_document
---

### Loading Packages

```{r}
pacman::p_load(ggpubr, 
               tidyr, 
               tidyverse, 
               stringr, 
               sqldf, 
               cld3,
               here,
               brms,
               brmstools,
               dplyr,
               metafor, 
               brms,
               tidybayes,
               ggdist,
               bayesplot)

CM <- modules::import("COVID_MODEL_helpfuns", attach = T, doc = T) #Loading my own DMI module
modules::reload(CM) # this simply reloads the module in case of any changes

```

### Loading Data

```{r}
tweet_list1 <- read_csv("~/Desktop/Lasse/Cognitive Science 4/Social and Cultural dynamics/tweet_list1.csv")
tweet_list_Danmark_11 <- read_csv("tweet_test1.csv")
tweet_list1$LangDetect <- NULL
tweet_list1$Date <- NULL
tweet_list1 <- rbind(tweet_list_Danmark_11, tweet_list1)
tweet_list1 = distinct(tweet_list1, Tweet, .keep_all = TRUE)
```

### Using Language Detection Algorrithm

```{r}
tweet_list1$Language = cld3::detect_language(tweet_list1$Tweet)
tweet_list1 =tweet_list1 %>% filter(Language %in% c("da", "sv", "no"))
```

### Isolating key sentiment words and cleaning the data

```{r}
tweet_list1$Subjectivity <- word(tweet_list1$Bert_Polarity, 2)
tweet_list1$Sentiment <- word(tweet_list1$Bert_Polarity, 4)


tweet_list1$Subjectivity <- gsub("'", "", tweet_list1$Subjectivity)
tweet_list1$Subjectivity <- gsub(",", "", tweet_list1$Subjectivity)

tweet_list1$Sentiment <- gsub("'", "", tweet_list1$Sentiment)
tweet_list1$Sentiment <- gsub("}", "", tweet_list1$Sentiment)
```

```{r}
write.csv(tweet_list1, "full_dat.csv")

tweet_list11 <- tweet_list1 %>% subset(Sentiment != "neutral")

tweet_list11 <- tweet_list11 %>% subset(Bert_Emotion != "No emotion") 
```


### Weighting sentiment scores

```{r}
tweet_list2 = tweet_list1 %>% 
  mutate(
    Likes_Pos = ifelse(Sentiment == "positive", Likes, ""),
    Likes_Neg = ifelse(Sentiment == "negative", Likes, ""),
    Likes_Neu = ifelse(Sentiment == "neutral", Likes, ""),
    Likes_Trust = ifelse(Bert_Emotion == "Tillid/Accept", Likes, ""),
    Likes_Trust = as.numeric(Likes_Trust),
    Likes_Anger = ifelse(Bert_Emotion == "Vrede/Irritation", Likes, ""),
    Likes_Anger = as.numeric(Likes_Anger),
    Likes_Neu = as.numeric(Likes_Neu),
    Likes_Pos = as.numeric(Likes_Pos),
    Likes_Neg = as.numeric(Likes_Neg),
    Retweets_Pos = ifelse(Sentiment == "positive", Retweets, ""),
    Retweets_Neg = ifelse(Sentiment == "negative", Retweets, ""),
    Retweets_Neu = ifelse(Sentiment == "neutral", Retweets, ""),
    
    Retweets_Trust = ifelse(Bert_Emotion == "Tillid/Accept", Retweets, ""),
    Retweets_Trust = as.numeric(Retweets_Trust),
    Retweets_Anger = ifelse(Bert_Emotion == "Vrede/Irritation", Retweets, ""),
    Retweets_Anger = as.numeric(Retweets_Anger),
    Retweets_Neu = as.numeric(Retweets_Neu),
    Retweets_Pos = as.numeric(Retweets_Pos),
    Retweets_Neg = as.numeric(Retweets_Neg),
    Neg = ifelse(Sentiment == "negative", 1, 0),
    Pos = ifelse(Sentiment == "positive", 1, 0)
    ) %>% 
  group_by(Date) %>% 
    summarise(
   Likes_Pos = Likes_Pos,
   Likes_Trust = Likes_Trust,
   Likes_Anger = Likes_Anger,
   Likes_Neg = Likes_Neg,
   Likes_Neu = Likes_Neu,
   Retweets_Anger = Retweets_Anger,
   Retweets_Trust = Retweets_Trust,
   Retweets_Pos = Retweets_Pos,
   Retweets_Neg = Retweets_Neg,
   Retweets_Neu = Retweets_Neu,
   Neg = Neg,
   Pos = Pos,
   Sent = paste0(Sentiment, collapse = ", "),
  Negative = str_count(Sent, pattern = "negative"),
  Positive = str_count(Sent, pattern = "positive"),
  Neutral = str_count(Sent, pattern = "neutral"),
#   Total_Likes = sum(Likes_Pos,Likes_Neg, na.rm = T),

  Total_Likes = sum(Likes_Pos,Likes_Neg,Likes_Neu, na.rm = T),
 # Total_Retweets = sum(Retweets_Pos,Retweets_Neg, na.rm = T),

   Total_Retweets = sum(Retweets_Pos,Retweets_Neg,Retweets_Neu, na.rm = T),
   Datetime = Datetime,
   Username = Username,
#   Weight_Pos = ifelse(Likes_Pos > 0, ((Likes_Pos / Total_Likes)), 0.00001) + ifelse(Retweets_Pos > 0, ((Retweets_Pos / Total_Retweets)), 0.00001),

     Weight_Pos =  ifelse(Retweets_Pos > 0, ((Retweets_Pos / Total_Retweets)*100), 0.00001),
    Weight_Neg =  ifelse(Retweets_Neg > 0, ((Retweets_Neg / Total_Retweets)*100), 0.00001),

   # Weight_Neg = ifelse(Likes_Neg > 0, ((Likes_Neg^-1 / Total_Likes)), 0.00001) + ifelse(Retweets_Neg > 0, ((Retweets_Neg / Total_Retweets)), 0.00001),
    total_tweet = sum(Negative, Positive, Neutral, na.rm = T),
   # total_tweet = sum(Negative, Positive, na.rm = T),
    Weight_Trust = ifelse(Likes_Trust > 0, ((Likes_Trust / Total_Likes)*1000), 0.00001) + ifelse(Retweets_Trust > 0, ((Retweets_Trust / Total_Retweets)*1000), 0.00001),
    Weight_Anger = ifelse(Likes_Anger > 0, ((Likes_Anger / Total_Likes)*1000), 0.00001) + ifelse(Retweets_Anger > 0, ((Retweets_Anger / Total_Retweets)*1000), 0.00001),
    Likes_Tot_em = Likes_Anger+Likes_Trust,
    Retweets_Tot_em = Retweets_Anger+Retweets_Trust,
    Bert_EM = paste0(Bert_Emotion, collapse = ", "),
    Contempt = str_count(Bert_EM, "Foragt/Modvilje"),
    No_Emotion = str_count(Bert_EM, "No emotion"),
    Joy = str_count(Bert_EM, "Glæde/Sindsro"),
    Interest = str_count(Bert_EM, "Forventning/Interrese"),
   Surprised = str_count(Bert_EM, "Overasket/Målløs"),
    Fear = str_count(Bert_EM, "Frygt/Bekymret"),
    Grief = str_count(Bert_EM, "Sorg/trist"),
    Anger = str_count(Bert_EM, "Vrede/Irritation"),
    Trust = str_count(Bert_EM, "Tillid/Accept"),
  #  Anger = (Anger/total_tweet)*Weight_Anger,
  #  Trust = (Trust/total_tweet)*Weight_Trust,
  #   No_Emotion = No_Emotion/total_tweet,
  #  Joy = Joy/total_tweet,
  # Interest = Interest/total_tweet,
  #  Surprised = Surprised/total_tweet,
  # Fear = Fear/total_tweet,
  #  Grief = Grief/total_tweet,
    Contempt1 = Contempt/total_tweet,
    Pos_Score = (Positive/total_tweet) * Weight_Pos,
    Neg_Score = (Negative/total_tweet)  * Weight_Neg
  )

tweet_list5 = tweet_list2 %>% group_by(Date) %>% 
     summarise(
      Total = sum(total_tweet),
      Likes_Trust = sum(Likes_Trust, na.rm = T),
      Likes_Anger = sum(Likes_Anger, na.rm = T),
      Retweets_Anger = sum(Retweets_Anger, na.rm = T),
      Retweets_Trust = sum(Retweets_Trust, na.rm = T),
      Total_Likes = sum(Likes_Tot_em, na.rm = T),
      Total_Retweets = sum(Retweets_Tot_em, na.rm = T),
  
      No_Emotion = sum(No_Emotion),
      Anger = sum(Anger),
      Contempt = sum(Contempt),
      Joy = sum(Joy),
      Interest = sum(Interest),
      Surprised = sum(Surprised),
      Fear = sum(Fear),
      Grief = sum(Grief),
      Trust = sum(Trust),
      
      Negative = sum(Negative),
      Positive = sum(Positive),
      
      Neg_Prop = Negative/Total,
      Pos_Prop = Positive/Total,
      Weight_Pos = sum(Weight_Pos, na.rm = T),
      Weight_Neg = sum(Weight_Neg, na.rm = T),
      
      Weight_Neg = sum(Weight_Neg, na.rm = T),

      
      Pos_Score = Pos_Prop*Weight_Pos,
      Neg_Score = Neg_Prop*Weight_Neg,
      
      Anger = Anger/Total,
      Trust = Trust/Total,
      No_Emotion = No_Emotion/Total,
      Joy = Joy/Total,
      Interest = Interest/Total,
      Surprised = Surprised/Total,
      Fear = Fear/Total,
      Grief = Grief/Total,
      Contempt = Contempt/Total,
      
     # Pos_Score = mean(Pos_Score, na.rm = T),
    #  Neg_Score = mean(Neg_Score, na.rm = T),
      FTG = Pos_Score-Neg_Score
     )

```

### Using my function to load and preprocess the DMI data

```{r}
data <- list.files(path = "/Users/lassehansen/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/DMI/", pattern = ".txt") %>%
    purrr::map_df(PreProc) #Using the module to load all DMI files (1 for each month) at a time

```


### Manually making sure that each Municipality is represented on each day 
#### It looks manual, however, it was the best way to double check that all municipalities had all dates

```{r Reading weather variables from DMI}

data <- read_csv("DMI_DATA_CLEAN_project.csv")

data$X1 <- NULL

sub <- subset(data, Kommune == "Tønder")
sub[, 2:7] <- "NA"
sub$Kommune <- "Kolding"
sub$Kolonne1 <- "10"

sub1 <- sub
sub1$Kommune <- "Ærø"
sub1$Kolonne1 <- "7"

sub2 <- sub1
sub2$Kommune <- "Albertslund"
sub2$Kolonne1 <- "19"

sub3 <- sub1
sub3$Kommune <- "Allerød"
sub3$Kolonne1 <- "19"

sub4 <- sub1
sub4$Kommune <- "Ballerup"
sub4$Kolonne1 <- "19"

sub5 <- sub1
sub5$Kommune <- "Brøndby"
sub5$Kolonne1 <- "19"

sub41 <- sub1
sub41$Kommune <- "Brønderslev"
sub41$Kolonne1 <- "1"

sub42 <- sub1
sub42$Kommune <- "Christiansø"
sub42$Kolonne1 <- "7"

sub44 <- sub1
sub44$Kommune <- "DMI"
sub44$Kolonne1 <- "19"


sub6 <- sub1
sub6$Kommune <- "Dragør"
sub6$Kolonne1 <- "19"

sub7 <- sub1
sub7$Kommune <- "Egedal"
sub7$Kolonne1 <- "19"

sub8 <- sub1
sub8$Kommune <- "Frederiksberg"
sub8$Kolonne1 <- "19"

sub9 <- sub1
sub9$Kommune <- "Frederikssund"
sub9$Kolonne1 <- "18"

sub10 <- sub1
sub10$Kommune <- "Gladsaxe"
sub10$Kolonne1 <- "19"

sub11 <- sub1
sub11$Kommune <- "Glostrup"
sub11$Kolonne1 <- "19"

sub12 <- sub1
sub12$Kommune <- "Halsnæs"
sub12$Kolonne1 <- "18"


sub13 <- sub1
sub13$Kommune <- "Herlev"
sub13$Kolonne1 <- "19"


sub7 <- sub1
sub7$Kommune <- "Helsingør"
sub7$Kolonne1 <- "19"


sub15 <- sub1
sub15$Kommune <- "Hørsholm"
sub15$Kolonne1 <- "19"


sub16 <- sub1
sub16$Kommune <- "Hvidovre"
sub16$Kolonne1 <- "19"


sub17 <- sub1
sub17$Kommune <- "Ishøj"
sub17$Kolonne1 <- "19"


sub18 <- sub1
sub18$Kommune <- "Jammerbugt"
sub18$Kolonne1 <- "2"

sub19 <- sub1
sub19$Kommune <- "Lejre"
sub19$Kolonne1 <- "18"


sub20 <- sub1
sub20$Kommune <- "Lemvig"
sub20$Kolonne1 <- "4"

sub21 <- sub1
sub21$Kommune <- "Lyngby-Taarbæk"
sub21$Kolonne1 <- "19"

sub22 <- sub1
sub22$Kommune <- "Rebild"
sub22$Kolonne1 <- "2"

sub23 <- sub1
sub23$Kommune <- "Rødovre"
sub23$Kolonne1 <- "19"

sub24 <- sub1
sub24$Kommune <- "Roskilde"
sub24$Kolonne1 <- "17"

sub25 <- sub1
sub25$Kommune <- "Rudersdal"
sub25$Kolonne1 <- "19"

sub26 <- sub1
sub26$Kommune <- "Solrød"
sub26$Kolonne1 <- "17"

sub27 <- sub1
sub27$Kommune <- "Sorø"
sub27$Kolonne1 <- "16"

sub28 <- sub1
sub28$Kommune <- "Stevns"
sub28$Kolonne1 <- "17"

sub29 <- sub1
sub29$Kommune <- "Vallensbæk"
sub29$Kolonne1 <- "19"

sub100 <- sub1
sub100$Kommune <- "Vejle"
sub100$Kolonne1 <- "11"

sub101 <- sub1
sub101$Kommune <- "Billund"
sub101$Kolonne1 <- "7"

sub45 <- sub1
sub45$Kommune <- "Greve"
sub45$Kolonne1 <- "17"

sub46 <- sub1
sub46$Kommune <- "Fredensborg"
sub46$Kolonne1 <- "19"

sub47 <- sub1
sub47$Kommune <- "Hillerød"
sub47$Kolonne1 <- "19"

sub48 <- sub1
sub48$Kommune <- "Høje-Taastrup"
sub48$Kolonne1 <- "19"

sub49 <- sub1
sub49$Kommune <- "Odense"
sub49$Kolonne1 <- "12"

sub50 <- sub1
sub50$Kommune <- "Langeland"
sub50$Kolonne1 <- "7"

sub51 <- sub1
sub51$Kommune <- "Faxe"
sub51$Kolonne1 <- "17"

sub52 <- sub1
sub52$Kommune <- "Ringsted"
sub52$Kolonne1 <- "18"

sub53 <- sub1
sub53$Kommune <- "Kerteminde"
sub53$Kolonne1 <- "12"

sub54 <- sub1
sub54$Kommune <- "Morsø"
sub54$Kolonne1 <- "12"

sub55 <- sub1
sub55$Kommune <- "Odder"
sub55$Kolonne1 <- "11"

sub56 <- sub1
sub56$Kommune <- "Vejen"
sub56$Kolonne1 <- "9"

sub57 <- sub1
sub57$Kommune <- "Mariagerfjord"
sub57$Kolonne1 <- "2"

sub58 <- sub1
sub58$Kommune <- "Struer"
sub58$Kolonne1 <- "4"

sub59 <- sub1
sub59$Kommune <- "Fredensborg"
sub59$Kolonne1 <- "19"

sub60 <- sub1
sub60$Kommune <- "Gribskov"
sub60$Kolonne1 <- "19"



bind <- rbind(sub, sub1, sub2, sub3, sub4, sub5, sub6, sub7, sub8, sub9, sub10, sub11, sub12, sub13, sub7, sub15, sub16, sub17, sub18, sub19, sub20, sub21, sub22, sub23, sub24, sub25, sub26, sub27, sub28, sub29, sub41, sub42, sub44, sub45, sub46, sub47, sub48, sub49, sub50, sub51, sub52, sub53, sub54, sub55, sub56, sub57, sub58, sub100, sub101, sub59, sub60)
kommune  <- read.csv("Kommuneposition (1).csv", sep = ";") #Loading in file about danish municipalities

bind$stationID <- as.numeric(bind$stationID)
bind$humidity_past1h <-  as.numeric(bind$humidity_past1h)
bind$precip_dur_past1h <-  as.numeric(bind$precip_dur_past1h)
bind$sun_last1h_glob <-  as.numeric(bind$sun_last1h_glob)
bind$temp_mean_past1h <-  as.numeric(bind$temp_mean_past1h)
bind$wind_speed_past1h <-  as.numeric(bind$wind_speed_past1h)

data111 <- left_join(data, kommune)
data111$Kommune_Nummer <- NULL
bind$Date <- as.Date(bind$Date)
bind$Kolonne1 <- as.integer(bind$Kolonne1)
data111$Date <- as.Date(data111$Date)
data10 <- rbind(bind, data111)
data10$Kommune = ifelse(data10$Kommune == "6052", "Lemvig", data10$Kommune)
data9 <- data10 %>% select(Date, Kommune)

```

### Reading Google Mobility Data - Cleaning it to match Municipality names

```{r Loading 2020 mobility data from google}
mobility <- read_csv("~/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/2020_DK_Region_Mobility_Report.csv")

mobility$CountDate <- as.numeric(mobility$date)

mobility$sub_region_2 <- gsub(" Municipality", "", mobility$sub_region_2)
mobility$sub_region_2 <- gsub(" ", "", mobility$sub_region_2)

mobility_region = mobility %>% filter(is.na(.$sub_region_2)) %>% filter(!is.na(.$sub_region_1)) %>% select(sub_region_1, date, 10:16)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Vesthimmerland", "Vesthimmerlands", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Brondby", "Brøndby", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Copenhagen", "København", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Nordfyn", "Nordfyns", mobility$sub_region_2)

mobility = mobility %>% filter(!is.na(sub_region_2))

mobility <- mobility %>% select(date, sub_region_1, sub_region_2, residential_percent_change_from_baseline, workplaces_percent_change_from_baseline, transit_stations_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, parks_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline)

colnames(mobility) <- c("Date", "Region", "Kommune", "Residential", "Workplace", "Transit", "Retail", "Park", "Grocery")
```

```{r Loading 2021 mobility data from google}
mobility1 <- read_csv("~/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/2021_DK_Region_Mobility_Report.csv")

mobility1$CountDate <- as.numeric(mobility1$date)

mobility1$sub_region_2 <- gsub(" Municipality", "", mobility1$sub_region_2)
mobility1$sub_region_2 <- gsub(" ", "", mobility1$sub_region_2)

mobility_region2020 = mobility1 %>% filter(is.na(.$sub_region_2)) %>% filter(!is.na(.$sub_region_1)) %>% select(sub_region_1, date, 10:16)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Vesthimmerland", "Vesthimmerlands", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Brondby", "Brøndby", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Copenhagen", "København", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Nordfyn", "Nordfyns", mobility1$sub_region_2)

mobility1 = mobility1 %>% filter(!is.na(sub_region_2))


mobility1 <- mobility1 %>% select(date, sub_region_1, sub_region_2, residential_percent_change_from_baseline, workplaces_percent_change_from_baseline, transit_stations_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, parks_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline)

colnames(mobility1) <- c("Date", "Region", "Kommune", "Residential", "Workplace", "Transit", "Retail", "Park", "Grocery")

mobility2 <- rbind(mobility, mobility1)
mobility20 <- rbind(mobility_region, mobility_region2020)
mobility11 <- left_join(data9, mobility2, by = c("Kommune", "Date"))
mobility20 = mobility20 %>% rename(Date = date)
mobility20 = mobility20 %>% rename(Region = sub_region_1)
```

### Using Region Identifier function to replace data if necessary

```{r}
CM <- modules::import("COVID_MODEL_helpfuns", attach = T, doc = T) #Loading my own DMI module

modules::reload(CM) # this simply reloads the module in case of any changes

mobility11 <- CM$Region_identifier(mobility11)
```

### If municipality does not contain data for a date, replace with region mean for the day

```{r Making sure every region has every date}

join = left_join(mobility11, mobility20, by = c("Region", "Date"))

join$Residential = ifelse(is.na(join$Residential), join$residential_percent_change_from_baseline, join$Residential)

join$Transit = ifelse(is.na(join$Transit), join$transit_stations_percent_change_from_baseline, join$Transit)

join$Retail = ifelse(is.na(join$Retail), join$retail_and_recreation_percent_change_from_baseline, join$Retail)

join$Workplace = ifelse(is.na(join$Workplace), join$workplaces_percent_change_from_baseline, join$Workplace)

mobility_dat = join %>% subset(.$Kommune != "Christiansø")
mobility_dat = mobility_dat %>% subset(.$Kommune != "DMI")
mobility_dat = mobility_dat %>% subset(.$Kommune !=5015)
mobility_dat = mobility_dat %>% select(Date, Kommune, Region, Transit, Residential, Retail, Workplace)

mobility_dat = mobility_dat %>% group_by(Date, Kommune) %>% 
  summarise(
    Transit = mean(Transit),
    Residential = mean(Residential),
    Retail = mean(Retail),
    Workplace = mean(Workplace)
  )
  
  
write_csv(mobility_dat, "mobility_dat.csv") #Data is saved as 'mobility_dat.csv' for your use
```

### Merging mobility data and weather data for each municipality

```{r Taking mean of weather variables per weather station in municipalities}
data1 <- full_join(data10, kommune, by = "Kommune", "Date")

data1$Kolonne1 <- ifelse(is.na(data1$Kolonne1.x), data1$Kolonne1.y, data1$Kolonne1.x)
data1$Kolonne1.y <- NULL
data1$Kolonne1.x <- NULL

data1 <- filter(data1, Kommune != "DMI") # Filtering out two datapoints that we do not need for analysis
data1 <- filter(data1, Kommune != "Christiansø")
data4 <- data1 %>% 
  select(Date, Kommune, humidity_past1h, precip_dur_past1h, sun_last1h_glob, temp_mean_past1h, Kolonne1, wind_speed_past1h) %>% 
  group_by(Kolonne1, Date) %>% 
  summarise(
    Humid = mean(humidity_past1h, na.rm = T),
    Precip = mean(precip_dur_past1h, na.rm = T),
    Sun = mean(sun_last1h_glob, na.rm = T),
    Temp = mean(temp_mean_past1h, na.rm = T),
    Wind = mean(wind_speed_past1h, na.rm = T),
    Kommune = Kommune
            )

data4 <- data4 %>% 
  group_by(Date, Kommune) %>% 
  summarise(
    Humid = mean(Humid, na.rm = T),
    Precip = mean(Precip, na.rm = T),
    Sun = mean(Sun, na.rm = T),
    Temp = mean(Temp, na.rm = T),
    Wind = mean(Wind, na.rm = T),
            )


data4 <- left_join(mobility_dat, data4, by = c("Kommune" = "Kommune", "Date" = "Date"))

data4 <- filter(data4, Kommune != "DMI")
```

```{r}
stringency <- read_csv("covid-stringency-index.csv")
stringency = stringency %>% filter(., Entity == "Denmark")
stringency$Date <- as.Date(stringency$Day)
stringency$Entity <- NULL
stringency$Code <- NULL
```


```{r}
Ulighed <- dst_get_data(table = "IFOR41" , ULLIG = "*",  Tid = "2019", KOMMUNEDK ="*")

Ulighed = Ulighed %>% pivot_wider(., 3, names_from = ULLIG, values_from = value) 

Ulighed = Ulighed %>% subset(.$KOMMUNEDK != "Hele landet") %>% rename(Kommune = KOMMUNEDK)
```


```{r}
join1 <- left_join(data4, stringency, by = "Date")

join2 = join1 %>%  subset(.$Date >= "2020-03-01" & .$Date < "2021-04-01")


join3 <- left_join(tweet_list5, join2)
join4 <- left_join(city, Ulighed)
join5 <- left_join(join4, BY4)
df <- left_join(join3, join5, by = c("Kommune"))
df = df %>% subset(!is.na(.$stringency_index))
df = df %>% subset(!is.na(.$Transit))

df$stringency_index_S <- (df$stringency_index-min(df$stringency_index))/(max(df$stringency_index)-min(df$stringency_index))*100
df$Transit_S <- (df$Transit-min(df$Transit))/(max(df$Transit)-min(df$Transit))*100
df$Residential_S <- (df$Residential-min(df$Residential))/(max(df$Residential)-min(df$Residential))*100
df$Disobidience <- ((df$Residential_S*-1) * (df$stringency_index_S)) + ((df$Transit_S) * (df$stringency_index_S))
df$Disobidience_INDEX <- (df$Disobidience-min(df$Disobidience))/(max(df$Disobidience)-min(df$Disobidience))*100

df2 = df %>% subset(!is.na(.$Disobidience))
```

### Scaling the variables, it is done one at a time as i have had problems with doing it in mutate

```{r}
df3 <- df2
df3$P90 = scale(df3$`P90/10 (Baseret på decilgrænser)`)
df3$Temp_S = scale(df3$Temp)
df3$Disobidience_S = scale(df3$Disobidience)
df3$Pos_Score_S = scale(df3$Pos_Score)
df3$Neg_Score_S = scale(df3$Neg_Score)
df3$month = lubridate::month(df3$Date)
```
### Using Hope Data

```{r}
X20210428 = X20210428 %>% subset(country == 1)

X20210428$maaling_month = ifelse(X20210428$maaling_month == 1, "01",
                          ifelse(X20210428$maaling_month == 2, "02",
                          ifelse(X20210428$maaling_month == 3, "03",
                          ifelse(X20210428$maaling_month == 4, "04",       
                          ifelse(X20210428$maaling_month == 5, "05",    
                          ifelse(X20210428$maaling_month == 6, "06",    
                          ifelse(X20210428$maaling_month == 7, "07",    
                          ifelse(X20210428$maaling_month == 8, "08",    
                          ifelse(X20210428$maaling_month == 9, "09",X20210428$maaling_month    
                                 )))))))))

X20210428$maaling_day = ifelse(X20210428$maaling_day == 1, "01",
                          ifelse(X20210428$maaling_day == 2, "02",
                          ifelse(X20210428$maaling_day == 3, "03",
                          ifelse(X20210428$maaling_day == 4, "04",       
                          ifelse(X20210428$maaling_day == 5, "05",    
                          ifelse(X20210428$maaling_day == 6, "06",    
                          ifelse(X20210428$maaling_day == 7, "07",    
                          ifelse(X20210428$maaling_day == 8, "08",    
                          ifelse(X20210428$maaling_day == 9, "09",X20210428$maaling_day    
                                 )))))))))


X20210428$Date = paste0(X20210428$maaling_year, "-", X20210428$maaling_month, "-",X20210428$maaling_day)

df_HOPE = X20210428 %>% subset(!is.na(.$gov_trust)) %>% mutate(High_Trust = ifelse(gov_trust >= 7 & gov_trust <12, "High_trust", "Low_trust")) %>%  
          mutate(Trust_High = str_count(High_Trust, "High_trust"),
          Trust_Low = str_count(High_Trust, "Low_trust")) 
df_HOPE1 = df_HOPE %>% 
          group_by(Date) %>% 
          summarise(
          Trust_High = sum(Trust_High),   
          Trust_Low = sum(Trust_Low),
          Total = Trust_High+Trust_Low,
          Prop_High = Trust_High/Total,
          .groups = 'drop'
          )
                                                                                                                                                                              df_HOPE2 = df_HOPE1 %>% select(Date, Prop_High) %>% mutate(Date = as.Date(Date))   
                                                                                                                                                                              
                                                                                                                                                                              
df4 = left_join(df3, df_HOPE2, by = "Date")

df4 = df4 %>% mutate(Prop_H = fill(Prop_High))

df4$Prop_High <- ifelse(df4$Date < "2020-03-18", 0.8907563, df4$Prop_High)

df4 = df4 %>% mutate(Prop_H = zoo::na.locf(Prop_High))
df4$Prop_HS = scale(df4$Prop_H)
```

### Building Model, Prior Predictive Check, Setting Priors

```{r}
Formula1 <- bf( Disobidience_S ~ Pos_Score_S + Neg_Score_S + Pos_Score_S*Temp_S + Neg_Score_S*Temp_S +P90 + (1|Kommune) + (1|Season))

get_prior(Formula1, data = df3, family = student())

Prior2 <- c( 
  prior(normal(0, 0.5), class = b, coef = Pos_Score_S),
  prior(normal(0, 0.5), class = b, coef = Neg_Score_S:Temp_S),
  prior(normal(0, 0.5), class = b, coef = Neg_Score_S),  
  prior(normal(0, 0.5), class = b, coef = Pos_Score_S:Temp_S ),
#  prior(normal(0, 0.5), class = b, coef = FTG_S:Precip_S),
  prior(normal(0,0.5), class = sd),
  prior(normal(0,0.5), class = Intercept),
  prior(normal(0, 0.5), class = b, coef = Temp_S),
#  prior(normal(0, 0.5), class = b, coef = Precip_S),
  prior(normal(0, 0.5), class = b, coef = P90),
#  prior(normal(0, 0.5), class = b, coef = Young_adults),
  prior(normal(0,0.5), class = sd, group = Season),
  prior(normal(0,0.5), class = sd, coef = Intercept, group = Season),
  prior(normal(0,0.5), class = sd, group = Kommune),
  prior(normal(0,0.5), class = sd, coef = Intercept, group = Kommune),
  prior(normal(0,0.5), class = sigma)
  )

m0_2 <- brm(
  Formula1,
  data = df3,
  family = student(),
  prior = Prior2,
  sample_prior = "only",
  backend="cmdstanr",
  chains = 4,
  cores = 4,
  iter = 4000,
  control = list(adapt_delta = 0.99, max_treedepth = 15)

)

pp_check(m0_2, nsamples = 100) + xlim(-5,5)

m1_4 <- brm(
  Formula1,
  data = df3,
  family = student(),
  prior = Prior2,
  sample_prior = T,
  backend="cmdstanr",
  chains = 4,
  cores = 4,
  iter = 4000,
  control = list(adapt_delta = 0.99, max_treedepth = 15)
  
)

pp_check(m1_4, nsamples = 100) + xlim(-5,5)
summary(m1_4)
```

# Building HOPE model


```{r}

m6 <- brm(Disobidience_S ~  Temp_S + Prop_HS + (1|Kommune) + (1|Season), data = df4, 
          prior = c(  prior(normal(0,0.5), class = sd),
                      prior(normal(0,0.5), class = Intercept),
                       prior(normal(0, 0.5), class = b, coef = Temp_S),
                        prior(normal(0,0.5), class = sd, group = Season),
                      prior(normal(0,0.5), class = sd, coef = Intercept, group = Season),
                       prior(normal(0,0.5), class = sd, group = Kommune),
                      prior(normal(0,0.5), class = sd, coef = Intercept, group = Kommune),
                       prior(normal(0,0.5), class = sigma)), 
            family = student(),
            sample_prior = T,
            backend="cmdstanr",
            chains = 2,
             cores = 2,
             iter = 4000,
             control = list(adapt_delta = 0.99, max_treedepth = 20)
)


m6 <- add_criterion(m6, c("loo", "waic"))

m8 <- brm(Disobidience_S ~  Temp_S + Pos_Score_S + (1|Kommune) + (1|Season), data = df4, 
          prior = c(  prior(normal(0,0.5), class = sd),
                      prior(normal(0,0.5), class = Intercept),
                       prior(normal(0, 0.5), class = b, coef = Temp_S),
                        prior(normal(0,0.5), class = sd, group = Season),
                      prior(normal(0,0.5), class = sd, coef = Intercept, group = Season),
                       prior(normal(0,0.5), class = sd, group = Kommune),
                      prior(normal(0,0.5), class = sd, coef = Intercept, group = Kommune),
                       prior(normal(0,0.5), class = sigma)), 
            family = student(),
            sample_prior = T,
            backend="cmdstanr",
            chains = 2,
             cores = 2,
             iter = 4000,
             control = list(adapt_delta = 0.99, max_treedepth = 20)
)

m8 <- add_criterion(m8, c("loo", "waic"))
loo_compare(m6, m8)
loo_model_weights(m6, m8)
```

### Destandardizing estimates

```{r}
destandardize <- function(coefficient, x, y){
        d =  ((coefficient*sd(y, na.rm = T)) / sd(x, na.rm = T) )
        return(d) 
        }

destandardize(-0.25, df3$Pos_Score, df3$Disobidience_INDEX)
destandardize(0.02, df3$Neg_Score, df3$Disobidience_INDEX)
destandardize(-0.15, df3$`P90/10 (Baseret på decilgrænser)`, df3$Disobidience_INDEX)
destandardize(0.54, df3$Temp, df3$Disobidience_INDEX)
```

### Plotting posterior updates

```{r}


ggplot(posterior) +
  theme_classic() +
  geom_density(aes(nu), fill="red", alpha=0.3) +
  geom_density(aes(prior_nu), fill="blue", alpha=0.5)

ggplot(posterior) +
  theme_classic() +
  geom_density(aes(b_Intercept), fill="red", alpha=0.3) +
  geom_density(aes(prior_Intercept), fill="blue", alpha=0.5) 

ggplot(posterior) +
  theme_classic() +
  geom_density(aes(sd_Season__Intercept), fill="red", alpha=0.3) +
  geom_density(aes(prior_sd_Season__Intercept), fill="blue", alpha=0.5) 
```

### Trace and rank plots

```{r}
library(viridis)
color_scheme_set("darkgray")
color_scheme_set("viridis")
```

### Plotting Conditonal effects

```{r}

c_eff <- conditional_effects(m1_4)
posterior <- posterior_samples(m1_4)

cond = as.data.frame(c_eff$`Pos_Score_S:Temp_S`)
cond1 = as.data.frame(c_eff$`Neg_Score_S:Temp_S`)
cond2 = as.data.frame(c_eff$Neg_Score_S)
cond3 = as.data.frame(c_eff$Pos_Score_S)
cond4 = as.data.frame(c_eff$P90)
cond5 = as.data.frame(c_eff$Temp_S)

cond$Temp_S = ifelse(cond$Temp_S == -1, "Low Temperature", 
                            ifelse(cond$Temp_S == 0, "Average Temperature", "High Temperature"))

cond$Temperature <- factor(cond$Temp_S, levels = c("Low Temperature", "Average Temperature", "High Temperature"))

cond1$Temp_S = ifelse(cond1$Temp_S == -1, "Low Temperature", 
                            ifelse(cond1$Temp_S == 0, "Average Temperature", "High Temperature"))

cond1$Temperature <- factor(cond1$Temp_S, levels = c("Low Temperature", "Average Temperature", "High Temperature"))

geom.text.size = 8
theme.size = (7/5) * geom.text.size

p1<- ggplot(cond, aes(x=Pos_Score_S, y=estimate__, group=Temperature, color = Temperature)) + 
  geom_line() +
#  geom_point()+
 # geom_smooth(method = "lm", formula = y~x) + 
  geom_ribbon(aes(ymin = estimate__-se__, ymax=estimate__+se__, fill = Temperature, alpha = 0.03)) +
  #stat_summary(geom="ribbon", fun.ymin= "lower__", fun.ymax="upper__", aes(fill=Temperature), alpha=0.3) +
#  geom_errorbar(aes(ymin=estimate__-se__, ymax=estimate__+se__), width=.3,)+
  scale_color_manual(values=c('#ffd882','#c4c4c4', '#15607a')) +
 # stat_smooth(method="loess", span=0.1, se=TRUE, aes(fill=Temperature), alpha=0.3) +
  scale_fill_manual(values=c('#ffd882','#c4c4c4', '#15607a')) +
  labs(x="Positive Resonating Polarity Interaction", y = "Social Disobidience") + theme(axis.text = element_text(size = theme.size))+ theme_light() + theme(legend.position = c(0.2, 0.25))  + scale_alpha(guide = 'none')

p1
p2 <- ggplot(posterior, aes(x = `b_Pos_Score_S:Temp_S`)) + labs(x="PRP:Temperature Coefficient Estimates", y = "Density") + geom_density() +  theme(axis.text = element_text(size = theme.size))+ theme_light()

p3<- ggplot(cond1, aes(x=Neg_Score_S, y=estimate__, group=Temperature, color = Temperature)) + 
  geom_line() +
#  geom_point()+
 # geom_smooth(method = "lm", formula = y~x) + 
  geom_ribbon(aes(ymin = estimate__-se__, ymax=estimate__+se__, fill = Temperature, alpha = 0.03)) +
  #stat_summary(geom="ribbon", fun.ymin= "lower__", fun.ymax="upper__", aes(fill=Temperature), alpha=0.3) +
#  geom_errorbar(aes(ymin=estimate__-se__, ymax=estimate__+se__), width=.3,)+
  scale_color_manual(values=c('#ffd882','#c4c4c4', '#15607a')) +
 # stat_smooth(method="loess", span=0.1, se=TRUE, aes(fill=Temperature), alpha=0.3) +
  scale_fill_manual(values=c('#ffd882','#c4c4c4', '#15607a')) +
  labs(x="Negative Resonating Polarity Interaction", y = "Social Disobidience") + theme(axis.text = element_text(size = theme.size))+ theme_light() + theme(legend.position = c(0.2, 0.25))+ scale_alpha(guide = 'none')

p4 <- ggplot(posterior, aes(x = `b_Neg_Score_S:Temp_S`)) + labs(x="NRP:Temperature Coefficient Estimates", y = "Density") + geom_density() +  theme(axis.text = element_text(size = theme.size))+ theme_light()


p5<- ggplot(cond4, aes(x=P90, y=estimate__)) + 
  geom_line() +
 #Q geom_point()+
 # geom_smooth(method = "lm", formula = y~x, level) + 
  geom_ribbon(aes(ymin = estimate__-se__, ymax=estimate__+se__, fill = '#ffd882', alpha = 0.03)) +
  #stat_summary(geom="ribbon", fun.ymin= "lower__", fun.ymax="upper__", aes(fill=Temperature), alpha=0.3) +
#  geom_errorbar(aes(ymin=estimate__-se__, ymax=estimate__+se__), width=.3,)+
  scale_color_manual(values=c('#ffd882')) +
 # stat_smooth(method="loess", span=0.1, se=TRUE, aes(fill=Temperature), alpha=0.3) +
  scale_fill_manual(values=c('#ffd882')) +
  labs(x="p90/10", y = "Social Disobidience") + theme(axis.text = element_text(size = theme.size))+ theme_light() + theme(legend.position = "none")+ scale_alpha(guide = 'none')

p6 <- ggplot(posterior, aes(x = b_P90)) + geom_density() + labs(x="p90/10 Coefficient Estimates", y = "Density") + theme(axis.text = element_text(size = theme.size))+ theme_light()

p7<- ggplot(cond3, aes(x=Pos_Score_S, y=estimate__)) + 
  geom_line() +
 #Q geom_point()+
 # geom_smooth(method = "lm", formula = y~x, level) + 
  geom_ribbon(aes(ymin = estimate__-se__, ymax=estimate__+se__, fill = '#ffd882', alpha = 0.03)) +
  #stat_summary(geom="ribbon", fun.ymin= "lower__", fun.ymax="upper__", aes(fill=Temperature), alpha=0.3) +
#  geom_errorbar(aes(ymin=estimate__-se__, ymax=estimate__+se__), width=.3,)+
  scale_color_manual(values=c('#ffd882')) +
 # stat_smooth(method="loess", span=0.1, se=TRUE, aes(fill=Temperature), alpha=0.3) +
  scale_fill_manual(values=c('#ffd882')) +
  labs(x="PRP", y = "Social Disobidience") + theme(axis.text = element_text(size = theme.size))+ theme_light() + theme(legend.position = "none")+ scale_alpha(guide = 'none')

p8 <- ggplot(posterior, aes(x = b_Pos_Score_S)) + geom_density()   + labs(x="PRP Coefficient Estimates", y = "Density") + theme(axis.text = element_text(size = theme.size))+ theme_light()

p9<- ggplot(cond2, aes(x=Neg_Score_S, y=estimate__)) + 
  geom_line() +
 #Q geom_point()+
 # geom_smooth(method = "lm", formula = y~x, level) + 
  geom_ribbon(aes(ymin = estimate__-se__, ymax=estimate__+se__, fill = '#ffd882', alpha = 0.03)) +
  #stat_summary(geom="ribbon", fun.ymin= "lower__", fun.ymax="upper__", aes(fill=Temperature), alpha=0.3) +
#  geom_errorbar(aes(ymin=estimate__-se__, ymax=estimate__+se__), width=.3,)+
  scale_color_manual(values=c('#ffd882')) +
 # stat_smooth(method="loess", span=0.1, se=TRUE, aes(fill=Temperature), alpha=0.3) +
  scale_fill_manual(values=c('#ffd882')) +
  labs(x="NRP", y = "Social Disobidience") + theme(axis.text = element_text(size = theme.size))+ theme_light() + theme(legend.position = "none")+ scale_alpha(guide = 'none')

p10 <- ggplot(posterior, aes(x = b_Neg_Score_S)) + geom_density()   + labs(x="NRP Coefficient Estimates", y = "Density") + theme(axis.text = element_text(size = theme.size))+ theme_light()

p11 <- ggplot(cond5, aes(x=Temp_S, y=estimate__, color = "Temp_S")) + 
  geom_line() +
 #Q geom_point()+
 # geom_smooth(method = "lm", formula = y~x, level) + 
  geom_ribbon(aes(ymin = estimate__-se__, ymax=estimate__+se__, fill = "grey70", alpha = 0.03)) +
  #stat_summary(geom="ribbon", fun.ymin= "lower__", fun.ymax="upper__", aes(fill=Temperature), alpha=0.3) +
 # geom_errorbar(aes(ymin=estimate__-se__, ymax=estimate__+se__), width=.3,)+
  scale_color_manual(values=c('#ffd882')) +
 # stat_smooth(method="loess", span=0.1, se=TRUE, aes(fill=Temperature), alpha=0.3) +
  scale_fill_manual(values=c('#ffd882')) +
  labs(x="Temperature", y = "Social Disobidience") + theme(axis.text = element_text(size = theme.size))+ theme_light() + theme(legend.position = "none")+ scale_alpha(guide = 'none')

p12 <- ggplot(posterior, aes(x = b_Temp_S)) + geom_density()   + labs(x="Temperature Coefficient Estimates", y = "Density") + theme(axis.text = element_text(size = theme.size))+ theme_light()

figure1 = ggarrange(p11, p12, p1, p2, p7, p8, p3, p4, labels = c("a","b", "c", "d", "e", "f", "g", "h"), ncol = 2, nrow = 4, common.legend = F) + theme(axis.text = element_text(size = theme.size))+ theme_light()

figure2 = ggarrange(p5, p6, p9, p10, labels = c("a","b", "c", "d"), ncol = 2, nrow = 2, common.legend = F) + theme(axis.text = element_text(size = theme.size))+ theme_light()

```

```{r}
forest(m1_4, pars = "Intercept", grouping = "Season")
forest(m1_4, pars = "Intercept", grouping = "Kommune")
```

### Making Dag

```{r}
#### Using daggity to make two dags, one that shows the overall 'system' and one with open paths:
pacman::p_load(dagitty, ggdag)
AI_DAG <- dagify(
       D ~ R + C,
       D ~ W,
       C ~ W,
       R~ C,
       labels = c("D" = "Social Disobidience", 
                  "C"= "COVID-19 Incidence Last Week",
                  "R" = "Restrictions",
                  "W" = "Weather"),
       exposure = "C",
       outcome = "D") %>% 
  tidy_dagitty()
#Plot of overall system
ggdag(AI_DAG, text = FALSE, use_labels = "label", shadow = TRUE) +
  theme_dag(base_size = 14) +
  theme(legend.position = "none", strip.text = element_blank()) + 
  # set node aesthetics
  scale_color_manual(values = "#0072B2", na.value = "grey80") + 
  # set label aesthetics
  scale_fill_manual(values = "#0072B2", na.value = "grey80") + 
  # set arrow aesthetics
  ggraph::scale_edge_color_manual(values = "#0072B2", na.value = "grey80") +
  ggtitle("Paths of Social Disobidience")
#Plot of paths
ggdag_paths(AI_DAG, text = FALSE, use_labels = "label", shadow = TRUE) +
  theme_dag(base_size = 14) +
  theme(legend.position = "none", strip.text = element_blank()) + 
  # set node aesthetics
  scale_color_manual(values = "#0072B2", na.value = "grey80") + 
  # set label aesthetics
  scale_fill_manual(values = "#0072B2", na.value = "grey80") + 
  # set arrow aesthetics
  ggraph::scale_edge_color_manual(values = "#0072B2", na.value = "grey80") +
  ggtitle("Paths of Social Disobidience")
```


