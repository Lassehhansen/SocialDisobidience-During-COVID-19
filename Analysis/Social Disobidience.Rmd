---
title: "Twitter Analysis Preprocessing"
author: "Lasse Hansen"
date: "5/12/2021"
output: html_document
---

### Loading Packages

```{r}
pacman::p_load(ggpubr, 
               tidyr, 
               tidyverse, 
               stringr, 
               sqldf, 
               cld3,
               here,
               brms,
               brmstools,
               dplyr,
               metafor, 
               brms,
               tidybayes,
               ggdist,
               bayesplot)

CM <- modules::import("COVID_MODEL_helpfuns", attach = T, doc = T) #Loading my own DMI module
modules::reload(CM) # this simply reloads the module in case of any changes

```

### Loading Data

```{r}
tweet_list1 <- read_csv("~/Desktop/Lasse/Cognitive Science 4/Social and Cultural dynamics/tweet_list1.csv")
tweet_list_Danmark_11 <- read_csv("tweet_test1.csv")
tweet_list1$LangDetect <- NULL
tweet_list1$Date <- NULL
tweet_list1 <- rbind(tweet_list_Danmark_11, tweet_list1)
tweet_list1 = distinct(tweet_list1, Tweet, .keep_all = TRUE)
```

### Using Language Detection Algorrithm

```{r}
tweet_list1$Language = cld3::detect_language(tweet_list1$Tweet)
tweet_list1 =tweet_list1 %>% filter(Language %in% c("da", "sv", "no"))
```

### Isolating key sentiment words and cleaning the data

```{r}
tweet_list1$Subjectivity <- word(tweet_list1$Bert_Polarity, 2)
tweet_list1$Sentiment <- word(tweet_list1$Bert_Polarity, 4)


tweet_list1$Subjectivity <- gsub("'", "", tweet_list1$Subjectivity)
tweet_list1$Subjectivity <- gsub(",", "", tweet_list1$Subjectivity)

tweet_list1$Sentiment <- gsub("'", "", tweet_list1$Sentiment)
tweet_list1$Sentiment <- gsub("}", "", tweet_list1$Sentiment)
```

### Weighting sentiment scores

```{r}
tweet_list2 = tweet_list1 %>% 
  mutate(
    Likes_Pos = ifelse(Sentiment == "positive", Likes, ""),
    Likes_Neg = ifelse(Sentiment == "negative", Likes, ""),
    Likes_Neu = ifelse(Sentiment == "neutral", Likes, ""),
    Likes_Neu = as.numeric(Likes_Neu),
    Likes_Pos = as.numeric(Likes_Pos),
    Likes_Neg = as.numeric(Likes_Neg),
    Retweets_Pos = ifelse(Sentiment == "positive", Retweets, ""),
    Retweets_Neg = ifelse(Sentiment == "negative", Retweets, ""),
    Retweets_Neu = ifelse(Sentiment == "neutral", Retweets, ""),
    Retweets_Neu = as.numeric(Retweets_Neu),
    Retweets_Pos = as.numeric(Retweets_Pos),
    Retweets_Neg = as.numeric(Retweets_Neg),
    Neg = ifelse(Sentiment == "negative", 1, 0),
    Pos = ifelse(Sentiment == "positive", 1, 0)
    ) %>% 
  group_by(Date) %>% 
    summarise(
   Likes_Pos = Likes_Pos,
   Likes_Neg = Likes_Neg,
   Likes_Neu = Likes_Neu,
   Retweets_Pos = Retweets_Pos,
   Retweets_Neg = Retweets_Neg,
   Retweets_Neu = Retweets_Neu,
   Neg = Neg,
   Pos = Pos,
   Sent = paste0(Sentiment, collapse = ", "),
  Negative = str_count(Sent, pattern = "negative"),
  Positive = str_count(Sent, pattern = "positive"),
  Neutral = str_count(Sent, pattern = "neutral"),
   Total_Likes = sum(Likes_Pos,Likes_Neg,Likes_Neu, na.rm = T),
   Total_Retweets = sum(Retweets_Pos,Retweets_Neg,Retweets_Neu, na.rm = T),
   Datetime = Datetime,
   Username = Username,
   Weight_Pos = ifelse(Likes_Pos > 0, ((Likes_Pos / Total_Likes)*100), 0.00001) + ifelse(Retweets_Pos > 0, ((Retweets_Pos / Total_Retweets)*100), 0.00001),
    Weight_Neg = ifelse(Likes_Neg > 0, ((Likes_Neg^-1 / Total_Likes) * 100), 0.00001) + ifelse(Retweets_Neg > 0, ((Retweets_Neg / Total_Retweets) * 100), 0.00001),
    total_tweet = sum(Negative, Positive, Neutral, na.rm = T),
    Contempt = str_count(Bert_Emotion, "Foragt/Modvilje"),
    No_Emotion = str_count(Bert_Emotion, "No emotion"),
    Joy = str_count(Bert_Emotion, "Glæde/Sindsro"),
    Interest = str_count(Bert_Emotion, "Forventning/Interrese"),
   Surprised = str_count(Bert_Emotion, "Overasket/Målløs"),
    Fear = str_count(Bert_Emotion, "Frygt/Bekymret"),
    Grief = str_count(Bert_Emotion, "Sorg/trist"),
    Anger = str_count(Bert_Emotion, "Vrede/Irritation"),
    Trust = str_count(Bert_Emotion, "Tillid/Accept"),
    Contempt = Contempt/total_tweet,
    Trust = Trust/total_tweet,
     No_Emotion = No_Emotion/total_tweet,
    Joy = Joy/total_tweet,
   Interest = Interest/total_tweet,
    Surprised = Surprised/total_tweet,
   Fear = Fear/total_tweet,
    Grief = Grief/total_tweet,
    Contempt = Contempt/total_tweet,
    Pos_Score = (Positive/total_tweet) * Weight_Pos,
    Neg_Score = (Negative/total_tweet)  * Weight_Neg
  )

tweet_list4 = tweet_list2 %>% group_by(Date) %>% 
     summarise(
      Contempt = sum(Contempt),
      Trust = sum(Trust),
      No_Emotion = sum(No_Emotion),
      Joy = sum(Joy),
      Interest = sum(Interest),
      Surprised = sum(Surprised),
      Fear = sum(Fear),
      Grief = sum(Grief),
      Anger = sum(Anger),
      Pos_Score = mean(Pos_Score, na.rm = T),
      Neg_Score = mean(Neg_Score, na.rm = T),
      Negative = sum(Negative),
      Positive = sum(Positive),
      FTG = Pos_Score-Neg_Score
     )

```

### Using my function to load and preprocess the DMI data

```{r}
data <- list.files(path = "/Users/lassehansen/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/DMI/", pattern = ".txt") %>%
    purrr::map_df(PreProc) #Using the module to load all DMI files (1 for each month) at a time

```


### Manually making sure that each Municipality is represented on each day 
#### It looks manual, however, it was the best way to double check that all municipalities had all dates

```{r Reading weather variables from DMI}

data <- read_csv("DMI_DATA_CLEAN_project.csv")

data$X1 <- NULL

sub <- subset(data, Kommune == "Tønder")
sub[, 2:7] <- "NA"
sub$Kommune <- "Kolding"
sub$Kolonne1 <- "10"

sub1 <- sub
sub1$Kommune <- "Ærø"
sub1$Kolonne1 <- "14"

sub2 <- sub1
sub2$Kommune <- "Albertslund"
sub2$Kolonne1 <- "19"

sub3 <- sub1
sub3$Kommune <- "Allerød"
sub3$Kolonne1 <- "19"

sub4 <- sub1
sub4$Kommune <- "Ballerup"
sub4$Kolonne1 <- "19"

sub5 <- sub1
sub5$Kommune <- "Brøndby"
sub5$Kolonne1 <- "19"

sub41 <- sub1
sub41$Kommune <- "Brønderslev"
sub41$Kolonne1 <- "1"

sub42 <- sub1
sub42$Kommune <- "Christiansø"
sub42$Kolonne1 <- "14"

sub44 <- sub1
sub44$Kommune <- "DMI"
sub44$Kolonne1 <- "19"


sub6 <- sub1
sub6$Kommune <- "Dragør"
sub6$Kolonne1 <- "19"

sub7 <- sub1
sub7$Kommune <- "Egedal"
sub7$Kolonne1 <- "19"

sub8 <- sub1
sub8$Kommune <- "Frederiksberg"
sub8$Kolonne1 <- "19"

sub9 <- sub1
sub9$Kommune <- "Frederikssund"
sub9$Kolonne1 <- "18"

sub10 <- sub1
sub10$Kommune <- "Gladsaxe"
sub10$Kolonne1 <- "19"

sub11 <- sub1
sub11$Kommune <- "Glostrup"
sub11$Kolonne1 <- "19"

sub12 <- sub1
sub12$Kommune <- "Halsnæs"
sub12$Kolonne1 <- "18"


sub13 <- sub1
sub13$Kommune <- "Herlev"
sub13$Kolonne1 <- "19"


sub14 <- sub1
sub14$Kommune <- "Helsingør"
sub14$Kolonne1 <- "19"


sub15 <- sub1
sub15$Kommune <- "Hørsholm"
sub15$Kolonne1 <- "19"


sub16 <- sub1
sub16$Kommune <- "Hvidovre"
sub16$Kolonne1 <- "19"


sub17 <- sub1
sub17$Kommune <- "Ishøj"
sub17$Kolonne1 <- "19"


sub18 <- sub1
sub18$Kommune <- "Jammerbugt"
sub18$Kolonne1 <- "2"

sub19 <- sub1
sub19$Kommune <- "Lejre"
sub19$Kolonne1 <- "18"


sub20 <- sub1
sub20$Kommune <- "Lemvig"
sub20$Kolonne1 <- "4"

sub21 <- sub1
sub21$Kommune <- "Lyngby-Taarbæk"
sub21$Kolonne1 <- "19"

sub22 <- sub1
sub22$Kommune <- "Rebild"
sub22$Kolonne1 <- "2"

sub23 <- sub1
sub23$Kommune <- "Rødovre"
sub23$Kolonne1 <- "19"

sub24 <- sub1
sub24$Kommune <- "Roskilde"
sub24$Kolonne1 <- "17"

sub25 <- sub1
sub25$Kommune <- "Rudersdal"
sub25$Kolonne1 <- "19"

sub26 <- sub1
sub26$Kommune <- "Solrød"
sub26$Kolonne1 <- "17"

sub27 <- sub1
sub27$Kommune <- "Sorø"
sub27$Kolonne1 <- "16"

sub28 <- sub1
sub28$Kommune <- "Stevns"
sub28$Kolonne1 <- "17"

sub29 <- sub1
sub29$Kommune <- "Vallensbæk"
sub29$Kolonne1 <- "19"

sub100 <- sub1
sub100$Kommune <- "Vejle"
sub100$Kolonne1 <- "11"

sub101 <- sub1
sub101$Kommune <- "Billund"
sub101$Kolonne1 <- "7"

sub45 <- sub1
sub45$Kommune <- "Greve"
sub45$Kolonne1 <- "17"

sub46 <- sub1
sub46$Kommune <- "Fredensborg"
sub46$Kolonne1 <- "19"

sub47 <- sub1
sub47$Kommune <- "Hillerød"
sub47$Kolonne1 <- "19"

sub48 <- sub1
sub48$Kommune <- "Høje-Taastrup"
sub48$Kolonne1 <- "19"

sub49 <- sub1
sub49$Kommune <- "Odense"
sub49$Kolonne1 <- "12"

sub50 <- sub1
sub50$Kommune <- "Langeland"
sub50$Kolonne1 <- "14"

sub51 <- sub1
sub51$Kommune <- "Faxe"
sub51$Kolonne1 <- "17"

sub52 <- sub1
sub52$Kommune <- "Ringsted"
sub52$Kolonne1 <- "18"

sub53 <- sub1
sub53$Kommune <- "Kerteminde"
sub53$Kolonne1 <- "12"

sub54 <- sub1
sub54$Kommune <- "Morsø"
sub54$Kolonne1 <- "12"

sub55 <- sub1
sub55$Kommune <- "Odder"
sub55$Kolonne1 <- "11"

sub56 <- sub1
sub56$Kommune <- "Vejen"
sub56$Kolonne1 <- "9"

sub57 <- sub1
sub57$Kommune <- "Mariagerfjord"
sub57$Kolonne1 <- "2"

sub58 <- sub1
sub58$Kommune <- "Struer"
sub58$Kolonne1 <- "4"

sub59 <- sub1
sub59$Kommune <- "Fredensborg"
sub59$Kolonne1 <- "19"

sub60 <- sub1
sub60$Kommune <- "Gribskov"
sub60$Kolonne1 <- "19"



bind <- rbind(sub, sub1, sub2, sub3, sub4, sub5, sub6, sub7, sub8, sub9, sub10, sub11, sub12, sub13, sub14, sub15, sub16, sub17, sub18, sub19, sub20, sub21, sub22, sub23, sub24, sub25, sub26, sub27, sub28, sub29, sub41, sub42, sub44, sub45, sub46, sub47, sub48, sub49, sub50, sub51, sub52, sub53, sub54, sub55, sub56, sub57, sub58, sub100, sub101, sub59, sub60)
kommune  <- read.csv("Kommuneposition (1).csv", sep = ";") #Loading in file about danish municipalities

bind$stationID <- as.numeric(bind$stationID)
bind$humidity_past1h <-  as.numeric(bind$humidity_past1h)
bind$precip_dur_past1h <-  as.numeric(bind$precip_dur_past1h)
bind$sun_last1h_glob <-  as.numeric(bind$sun_last1h_glob)
bind$temp_mean_past1h <-  as.numeric(bind$temp_mean_past1h)
bind$wind_speed_past1h <-  as.numeric(bind$wind_speed_past1h)

data111 <- left_join(data, kommune)
data111$Kommune_Nummer <- NULL
bind$Date <- as.Date(bind$Date)
bind$Kolonne1 <- as.integer(bind$Kolonne1)
data111$Date <- as.Date(data111$Date)
data10 <- rbind(bind, data111)
data10$Kommune = ifelse(data10$Kommune == "6052", "Lemvig", data10$Kommune)
data9 <- data10 %>% select(Date, Kommune)

```

### Reading Google Mobility Data - Cleaning it to match Municipality names

```{r Loading 2020 mobility data from google}
mobility <- read_csv("~/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/2020_DK_Region_Mobility_Report.csv")

mobility$CountDate <- as.numeric(mobility$date)

mobility$sub_region_2 <- gsub(" Municipality", "", mobility$sub_region_2)
mobility$sub_region_2 <- gsub(" ", "", mobility$sub_region_2)

mobility_region = mobility %>% filter(is.na(.$sub_region_2)) %>% filter(!is.na(.$sub_region_1)) %>% select(sub_region_1, date, 10:16)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Vesthimmerland", "Vesthimmerlands", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Brondby", "Brøndby", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Copenhagen", "København", mobility$sub_region_2)

mobility$sub_region_2 <- ifelse(mobility$sub_region_2 == "Nordfyn", "Nordfyns", mobility$sub_region_2)

mobility = mobility %>% filter(!is.na(sub_region_2))

mobility <- mobility %>% select(date, sub_region_1, sub_region_2, residential_percent_change_from_baseline, workplaces_percent_change_from_baseline, transit_stations_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, parks_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline)

colnames(mobility) <- c("Date", "Region", "Kommune", "Residential", "Workplace", "Transit", "Retail", "Park", "Grocery")
```

```{r Loading 2021 mobility data from google}
mobility1 <- read_csv("~/Desktop/Lasse/Cognitive Science 3 Semester/Causal Inference/Causal-Inference/2021_DK_Region_Mobility_Report.csv")

mobility1$CountDate <- as.numeric(mobility1$date)

mobility1$sub_region_2 <- gsub(" Municipality", "", mobility1$sub_region_2)
mobility1$sub_region_2 <- gsub(" ", "", mobility1$sub_region_2)

mobility_region2020 = mobility1 %>% filter(is.na(.$sub_region_2)) %>% filter(!is.na(.$sub_region_1)) %>% select(sub_region_1, date, 10:16)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Vesthimmerland", "Vesthimmerlands", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Brondby", "Brøndby", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Copenhagen", "København", mobility1$sub_region_2)

mobility1$sub_region_2 <- ifelse(mobility1$sub_region_2 == "Nordfyn", "Nordfyns", mobility1$sub_region_2)

mobility1 = mobility1 %>% filter(!is.na(sub_region_2))


mobility1 <- mobility1 %>% select(date, sub_region_1, sub_region_2, residential_percent_change_from_baseline, workplaces_percent_change_from_baseline, transit_stations_percent_change_from_baseline, retail_and_recreation_percent_change_from_baseline, parks_percent_change_from_baseline, grocery_and_pharmacy_percent_change_from_baseline)

colnames(mobility1) <- c("Date", "Region", "Kommune", "Residential", "Workplace", "Transit", "Retail", "Park", "Grocery")

mobility2 <- rbind(mobility, mobility1)
mobility20 <- rbind(mobility_region, mobility_region2020)
mobility11 <- left_join(data9, mobility2, by = c("Kommune", "Date"))
mobility20 = mobility20 %>% rename(Date = date)
mobility20 = mobility20 %>% rename(Region = sub_region_1)
```

### Using Region Identifier function to replace data if necessary

```{r}
CM <- modules::import("COVID_MODEL_helpfuns", attach = T, doc = T) #Loading my own DMI module

modules::reload(CM) # this simply reloads the module in case of any changes

mobility11 <- CM$Region_identifier(mobility11)
```

### If municipality does not contain data for a date, replace with region mean for the day

```{r Making sure every region has every date}

join = left_join(mobility11, mobility20, by = c("Region", "Date"))

join$Residential = ifelse(is.na(join$Residential), join$residential_percent_change_from_baseline, join$Residential)

join$Transit = ifelse(is.na(join$Transit), join$transit_stations_percent_change_from_baseline, join$Transit)

join$Retail = ifelse(is.na(join$Retail), join$retail_and_recreation_percent_change_from_baseline, join$Retail)

join$Workplace = ifelse(is.na(join$Workplace), join$workplaces_percent_change_from_baseline, join$Workplace)

mobility_dat = join %>% subset(.$Kommune != "Christiansø")
mobility_dat = mobility_dat %>% subset(.$Kommune != "DMI")
mobility_dat = mobility_dat %>% subset(.$Kommune !=5015)
mobility_dat = mobility_dat %>% select(Date, Kommune, Region, Transit, Residential, Retail, Workplace)

mobility_dat = mobility_dat %>% group_by(Date, Kommune) %>% 
  summarise(
    Transit = mean(Transit),
    Residential = mean(Residential),
    Retail = mean(Retail),
    Workplace = mean(Workplace)
  )
  
  
write_csv(mobility_dat, "mobility_dat.csv") #Data is saved as 'mobility_dat.csv' for your use
```

### Merging mobility data and weather data for each municipality

```{r Taking mean of weather variables per weather station in municipalities}
data1 <- full_join(data10, kommune, by = "Kommune", "Date")

data1$Kolonne1 <- ifelse(is.na(data1$Kolonne1.x), data1$Kolonne1.y, data1$Kolonne1.x)
data1$Kolonne1.y <- NULL
data1$Kolonne1.x <- NULL

data1 <- filter(data1, Kommune != "DMI") # Filtering out two datapoints that we do not need for analysis
data1 <- filter(data1, Kommune != "Christiansø")
data4 <- data1 %>% 
  select(Date, Kommune, humidity_past1h, precip_dur_past1h, sun_last1h_glob, temp_mean_past1h, Kolonne1, wind_speed_past1h) %>% 
  group_by(Kolonne1, Date) %>% 
  summarise(
    Humid = mean(humidity_past1h, na.rm = T),
    Precip = mean(precip_dur_past1h, na.rm = T),
    Sun = mean(sun_last1h_glob, na.rm = T),
    Temp = mean(temp_mean_past1h, na.rm = T),
    Wind = mean(wind_speed_past1h, na.rm = T),
    Kommune = Kommune
            )

data4 <- data4 %>% 
  group_by(Date, Kommune) %>% 
  summarise(
    Humid = mean(Humid, na.rm = T),
    Precip = mean(Precip, na.rm = T),
    Sun = mean(Sun, na.rm = T),
    Temp = mean(Temp, na.rm = T),
    Wind = mean(Wind, na.rm = T),
            )


data4 <- left_join(mobility_dat, data4, by = c("Kommune" = "Kommune", "Date" = "Date"))

data4 <- filter(data4, Kommune != "DMI")
```

```{r}
stringency <- read_csv("covid-stringency-index.csv")
stringency = stringency %>% filter(., Entity == "Denmark")
stringency$Date <- as.Date(stringency$Day)
stringency$Entity <- NULL
stringency$Code <- NULL
```

```{r}
join1 <- left_join(mobility_dat, stringency, by = "Date")

join2 = join1 %>%  subset(.$Date >= "2020-03-01" & .$Date < "2021-04-01")
join3 <- left_join(tweet_list4, join2)

df <- left_join(data4, join3, by = c("Date", "Kommune"))
df$Disobidience <- ((df$Residential.x *-1/ sd(df$Residential.x*-1) )* (df$stringency_index / sd(df$stringency_index, na.rm = T))) + ( (df$Transit.x / sd(df$Transit.x, na.rm = T))* (df$stringency_index/sd(df$stringency_index, na.rm = T)))
df2 = df %>% subset(!is.na(.$Disobidience))
write_csv(df2, "full_data_set.csv") 
```


### Scaling the variables, it is done one at a time as i have had problems with doing it in mutate

```{r}

df3 <- df2
df3$Temp_S = scale(df3$Temp)
df3$Precip_S = scale(df3$Precip)
df3$Disobidience_S = scale(df3$Disobidience)
df3$Pos_Score_S = scale(df3$Pos_Score)
df3$Neg_Score_S = scale(df3$Neg_Score)
df3$FTG_S = scale(df3$FTG)
df3$Contempt = scale(df3$Contempt)
df3$Trust = scale(df3$Trust)
df3$Sun = scale(df3$Sun)
df3$month = lubridate::month(df3$Date)

df3$week = lubridate::week(df3$Date)
df3$year = lubridate::year(df3$Date)
df3$Season = lubridate::quarter(df3$Date)
df3$Season <- as.factor(df3$Season)
quarter
df3$Week <- paste(df3$year, "_", df3$week, sep = "")
df3$Month <- paste(df3$year, "_", df3$month, sep = "")
df3$Month <- as.factor(df3$Month)
```


### Building Model, Prior Predictive Check, Setting Priors

```{r}
Formula1 <- bf( Disobidience_S ~ FTG_S*Temp_S + FTG_S*Precip_S + (1 |Kommune))
get_prior(Formula1, data = df3, family = student())

Prior2 <- c( 
  prior(normal(0, 0.5), class = b, coef = FTG_S),
  prior(normal(0, 0.5), class = b, coef = FTG_S:Temp_S),
  prior(normal(0, 0.5), class = b, coef = FTG_S:Precip_S),
  prior(normal(0,0.5), class = sd),
  prior(normal(0,0.5), class = Intercept),
  prior(normal(0, 0.5), class = b, coef = Temp_S),
  prior(normal(0, 0.5), class = b, coef = Precip_S),
  prior(normal(0,0.2), class = sd, group = Kommune),
  prior(normal(0,0.2), class = sd, coef = Intercept, group = Kommune),
  prior(normal(0,0.5), class = sigma)
  )

m0_2 <- brm(
  Formula1,
  data = df3,
  family = student(),
  prior = Prior2,
  sample_prior = "only",
  backend="cmdstanr",
  chains = 2,
  cores = 2,
  control = list(adapt_delta = 0.99, max_treedepth = 15)

)

pp_check(m0_2, nsamples = 100) + xlim(-5,5)

m1_2 <- brm(
  Formula1,
  data = df3,
  family = student(),
  prior = Prior2,
  sample_prior = T,
  backend="cmdstanr",
  chains = 2,
  cores = 2,
#  iter = 4000,
  control = list(adapt_delta = 0.99, max_treedepth = 15)
  
)

pp_check(m1_2, nsamples = 100)
summary(m1_2)
```

### Posterior Update Plots

```{r}
posterior <- posterior_samples(m1_2)
ggplot(posterior) +
  theme_classic() +
  geom_density(aes(prior_b_Temp_S), fill="red", alpha=0.3) +
  geom_density(aes(b_Temp_S), fill="blue", alpha=0.5)
ggplot(posterior) +
  theme_classic() +
  geom_density(aes(prior_b_FTG_S), fill="red", alpha=0.3) +
  geom_density(aes(b_FTG_S), fill="blue", alpha=0.5) 
ggplot(posterior) +
  theme_classic() +
  geom_density(aes(`prior_b_FTG_S:Temp_S`), fill="red", alpha=0.3) +
  geom_density(aes(`b_FTG_S:Temp_S`), fill="blue", alpha=0.5) + xlim(-1,1)
```

### Conditional Plots

```{r}
plot(conditional_effects(m1), ask = FALSE)
```

### Plotting municipality heterogeneity

```{r}
forest(m1, pars = "Intercept", grouping = "Kommune")
```

### Checking chains

```{r}
mcmc_trace(m1, pars = "Intercept")
mcmc_rank_overlay(m1, pars = "Intercept")
```

```{r}
plot1 = ggplot(data = df3, aes(x = Date)) +
  geom_smooth(aes(y = FTG_S, colour = "FTG_S", level = 0.95)) + 
  geom_smooth(aes(y = Disobidience_S, colour = "Disobidience_S", level = 0.95))
```
